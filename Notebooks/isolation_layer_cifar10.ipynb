{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "!rm -rf ./logs/cifar10/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072, 10)\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = tfds.load('cifar10', split=['train','test'], as_supervised=True, batch_size = -1)\n",
    "\n",
    "x_train, y_train = tfds.as_numpy(train_ds)\n",
    "x_test, y_test = tfds.as_numpy(test_ds)\n",
    "\n",
    "n = x_train.shape[0]\n",
    "n_dims = tf.math.cumprod(x_train.shape[1:])[-1].numpy()\n",
    "\n",
    "# Preprocess the data by flattening & scaling it\n",
    "x_train = x_train.reshape(-1, 32*32*3).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(-1, 32*32*3).astype(\"float32\") / 255\n",
    "\n",
    "# Categorical (one hot) encoding of the labels\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "_, n_classes = y_train.shape\n",
    "\n",
    "print((n, n_dims, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2930 - acc: 0.3924 - val_loss: 0.2764 - val_acc: 0.4234\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2413 - acc: 0.5092 - val_loss: 0.2957 - val_acc: 0.4271\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2257 - acc: 0.5569 - val_loss: 0.2740 - val_acc: 0.4677\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2133 - acc: 0.5901 - val_loss: 0.2877 - val_acc: 0.4603\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.2049 - acc: 0.6100 - val_loss: 0.3096 - val_acc: 0.4426\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2017 - acc: 0.6273 - val_loss: 0.3104 - val_acc: 0.4471\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.1941 - acc: 0.6436 - val_loss: 0.3172 - val_acc: 0.4455\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.1902 - acc: 0.6577 - val_loss: 0.3265 - val_acc: 0.4546\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1856 - acc: 0.6672 - val_loss: 0.3316 - val_acc: 0.4461\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.1843 - acc: 0.6728 - val_loss: 0.3360 - val_acc: 0.4525\n",
      "INFO:tensorflow:Assets written to: ./logs/cifar10/linear-8192-20230306-105525/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/cifar10/linear-8192-20230306-105525/model\\assets\n"
     ]
    }
   ],
   "source": [
    "RandomFourierFeatures = keras.layers.experimental.RandomFourierFeatures\n",
    "\n",
    "model_svm = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(n_dims,)),\n",
    "        RandomFourierFeatures(\n",
    "            output_dim=8192, scale=10.0, kernel_initializer=\"gaussian\"\n",
    "        ),\n",
    "        layers.Dense(units=n_classes),\n",
    "    ]\n",
    ")\n",
    "model_svm.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.hinge,\n",
    "    metrics=[keras.metrics.CategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "modeldir = \"./logs/cifar10/linear-8192-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_svm.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=modeldir+\"/log\",\n",
    "            histogram_freq=1,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "model_svm.save(modeldir + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_samples(X, psi, t=1000):\n",
    "    n, _ = X.shape\n",
    "    return [\n",
    "        tf.gather_nd(\n",
    "            indices=tf.expand_dims(tf.random.shuffle(tf.range(n))[:psi], 1), params=X\n",
    "        ).numpy()\n",
    "        for _ in range(t)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tf_ann(X, samples, p=2, soft=True):\n",
    "    m_dis = None\n",
    "    for i in range(samples.shape[0]):\n",
    "        i_sample = samples[i : i + 1, :]\n",
    "        l_dis = tf.math.reduce_sum((X - i_sample) ** p, axis=1, keepdims=True) ** (\n",
    "            1 / p\n",
    "        )\n",
    "        if m_dis is None:\n",
    "            m_dis = l_dis\n",
    "        else:\n",
    "            m_dis = tf.concat([m_dis, l_dis], 1)\n",
    "\n",
    "    if soft:\n",
    "        feature_map = tf.nn.softmax(-m_dis, axis=0)\n",
    "    else:\n",
    "        feature_map = tf.one_hot(tf.math.argmax(-m_dis, axis=1), samples.shape[0])\n",
    "    # l_dis_min = tf.math.reduce_sum(m_dis * feature_map, axis=0)\n",
    "    return feature_map\n",
    "\n",
    "\n",
    "class IsolationEncodingLayer(layers.Layer):\n",
    "    def __init__(self, samples, p=2, soft=True, **kwargs):\n",
    "        super(IsolationEncodingLayer, self).__init__(**kwargs)\n",
    "        self.samples = samples\n",
    "        self.p = p\n",
    "        self.soft = soft\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return _tf_ann(inputs, self.samples, self.p, self.soft)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"samples\": self.samples,\n",
    "                \"p\": self.p,\n",
    "                \"soft\": self.soft,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(t_samples, p=2, soft=True):\n",
    "    t = len(t_samples)\n",
    "    if t <= 0:\n",
    "        raise ValueError(\"t <= 0\")\n",
    "    _, dims = t_samples[0].shape\n",
    "\n",
    "    inputs = keras.Input(name=\"inputs_x\", shape=(dims,))\n",
    "    lambdas = [\n",
    "        IsolationEncodingLayer(t_samples[i], p=p, soft=soft, name=\"ann_{}\".format(i))(\n",
    "            inputs\n",
    "        )\n",
    "        for i in range(t)\n",
    "    ]\n",
    "    concatenated = layers.Concatenate(axis=1, name=\"concatenated\")(lambdas)\n",
    "    outputs = layers.Dense(units=10, name=\"outputs_y\")(concatenated)\n",
    "\n",
    "    model = keras.Model(name=\"isolation_encoding\", inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=keras.losses.hinge,\n",
    "        metrics=[keras.metrics.CategoricalAccuracy(name=\"acc\")],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_samples = gen_samples(x_train, psi=16, t=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hard_16_500 = build_model(t_samples, soft=False)\n",
    "modeldir = \"./logs/cifar10/hard-16x500-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_hard_16_500.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(log_dir=modeldir + \"/log\", histogram_freq=1)\n",
    "    ],\n",
    ")\n",
    "model_hard_16_500.save(modeldir + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_soft_16_500 = build_model(t_samples, soft=True)\n",
    "modeldir = \"./logs/cifar10/soft-16x500-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_soft_16_500.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(log_dir=modeldir + \"/log\", histogram_freq=1)\n",
    "    ],\n",
    ")\n",
    "model_soft_16_500.save(modeldir + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_samples = gen_samples(x_train, psi=160, t=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hard_160_50 = build_model(t_samples, soft=False)\n",
    "modeldir = \"./logs/cifar10/hard-160x50-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_hard_160_50.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(log_dir=modeldir + \"/log\", histogram_freq=1)\n",
    "    ],\n",
    ")\n",
    "model_hard_160_50.save(modeldir + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_soft_160_50 = build_model(t_samples, soft=True)\n",
    "modeldir = \"./logs/cifar10/soft-160x50-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_soft_160_50.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(log_dir=modeldir + \"/log\", histogram_freq=1)\n",
    "    ],\n",
    ")\n",
    "model_soft_160_50.save(modeldir + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a47f39fd070b48c46d7ad468a6f203b63097621f5a6c21be0934a2bf61a8c8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
