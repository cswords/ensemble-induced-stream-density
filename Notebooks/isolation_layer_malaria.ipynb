{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "image_w, image_h = 32, 32\n",
    "\n",
    "!rm -rf ./logs/malaria/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:  27558 n_classes:  2 dims:  3072\n"
     ]
    }
   ],
   "source": [
    "(ds_train_raw, ds_test_raw), ds_info = tfds.load(\n",
    "    \"malaria\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\"],\n",
    "    shuffle_files=False,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "n_classes = ds_info.features[\"label\"].num_classes\n",
    "n = ds_info.splits[\"train\"].num_examples\n",
    "\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = layers.Resizing(image_h, image_w)(image)\n",
    "    image = tf.reshape(image, [-1])\n",
    "    label = tf.one_hot(tf.cast(label, tf.int32), n_classes)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "ds_train_normalized = ds_train_raw.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE\n",
    ").cache()\n",
    "\n",
    "ds_test_normalized = ds_test_raw.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE\n",
    ").cache()\n",
    "\n",
    "\n",
    "def prepare(ds, batch_size=batch_size):\n",
    "    return ds.shuffle(n).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "dims = list(ds_train_normalized.take(1))[0][0].shape[0]\n",
    "\n",
    "print(\"n: \", n, \"n_classes: \", n_classes, \"dims: \", dims)\n",
    "\n",
    "\n",
    "def minmax_reducer(current, input):\n",
    "    X, _ = input\n",
    "    return (\n",
    "        tf.reduce_min([current[0], X], axis=0),\n",
    "        tf.reduce_max([current[0], X], axis=0),\n",
    "    )\n",
    "\n",
    "\n",
    "x0, _ = list(ds_train_normalized.take(1))[0]\n",
    "min_train, max_train = ds_train_normalized.reduce((x0, x0), minmax_reducer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "345/345 [==============================] - 8s 13ms/step - loss: 0.7756 - acc: 0.6638 - val_loss: 0.7355 - val_acc: 0.6785\n",
      "Epoch 2/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6947 - acc: 0.7019 - val_loss: 0.7198 - val_acc: 0.6840\n",
      "Epoch 3/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6681 - acc: 0.7142 - val_loss: 0.7241 - val_acc: 0.6885\n",
      "Epoch 4/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6540 - acc: 0.7207 - val_loss: 0.7469 - val_acc: 0.6696\n",
      "Epoch 5/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6420 - acc: 0.7270 - val_loss: 0.7224 - val_acc: 0.6845\n",
      "Epoch 6/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6350 - acc: 0.7298 - val_loss: 0.7289 - val_acc: 0.6774\n",
      "Epoch 7/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6309 - acc: 0.7311 - val_loss: 0.7046 - val_acc: 0.6936\n",
      "Epoch 8/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6212 - acc: 0.7345 - val_loss: 0.7263 - val_acc: 0.6948\n",
      "Epoch 9/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6190 - acc: 0.7405 - val_loss: 0.7126 - val_acc: 0.6914\n",
      "Epoch 10/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6174 - acc: 0.7357 - val_loss: 0.7216 - val_acc: 0.6890\n",
      "Epoch 11/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6141 - acc: 0.7386 - val_loss: 0.7224 - val_acc: 0.6887\n",
      "Epoch 12/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6132 - acc: 0.7423 - val_loss: 0.7183 - val_acc: 0.6898\n",
      "Epoch 13/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6145 - acc: 0.7377 - val_loss: 0.7310 - val_acc: 0.6849\n",
      "Epoch 14/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6127 - acc: 0.7417 - val_loss: 0.7237 - val_acc: 0.6919\n",
      "Epoch 15/30\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.6104 - acc: 0.7427 - val_loss: 0.7347 - val_acc: 0.6847\n",
      "Epoch 16/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6055 - acc: 0.7440 - val_loss: 0.7478 - val_acc: 0.6758\n",
      "Epoch 17/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6098 - acc: 0.7429 - val_loss: 0.7475 - val_acc: 0.6832\n",
      "Epoch 18/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6092 - acc: 0.7450 - val_loss: 0.7421 - val_acc: 0.6807\n",
      "Epoch 19/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6059 - acc: 0.7465 - val_loss: 0.7315 - val_acc: 0.6836\n",
      "Epoch 20/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6039 - acc: 0.7469 - val_loss: 0.7298 - val_acc: 0.6896\n",
      "Epoch 21/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6053 - acc: 0.7455 - val_loss: 0.7299 - val_acc: 0.6870\n",
      "Epoch 22/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6049 - acc: 0.7452 - val_loss: 0.7634 - val_acc: 0.6756\n",
      "Epoch 23/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6094 - acc: 0.7440 - val_loss: 0.7474 - val_acc: 0.6852\n",
      "Epoch 24/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6064 - acc: 0.7462 - val_loss: 0.7425 - val_acc: 0.6823\n",
      "Epoch 25/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6033 - acc: 0.7484 - val_loss: 0.7372 - val_acc: 0.6878\n",
      "Epoch 26/30\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.6016 - acc: 0.7461 - val_loss: 0.7472 - val_acc: 0.6874\n",
      "Epoch 27/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6091 - acc: 0.7454 - val_loss: 0.7405 - val_acc: 0.6883\n",
      "Epoch 28/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6045 - acc: 0.7493 - val_loss: 0.7454 - val_acc: 0.6836\n",
      "Epoch 29/30\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.6111 - acc: 0.7426 - val_loss: 0.7421 - val_acc: 0.6852\n",
      "Epoch 30/30\n",
      "345/345 [==============================] - 2s 6ms/step - loss: 0.6028 - acc: 0.7491 - val_loss: 0.7390 - val_acc: 0.6858\n",
      "INFO:tensorflow:Assets written to: ./logs/malaria/linear-8192-20230309-215525/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/malaria/linear-8192-20230309-215525/model\\assets\n"
     ]
    }
   ],
   "source": [
    "RandomFourierFeatures = keras.layers.experimental.RandomFourierFeatures\n",
    "\n",
    "model_svm = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(dims,)),\n",
    "        RandomFourierFeatures(\n",
    "            output_dim=2000, scale=10.0, kernel_initializer=\"gaussian\"\n",
    "        ),\n",
    "        layers.Dense(units=n_classes),\n",
    "    ]\n",
    ")\n",
    "model_svm.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.hinge,\n",
    "    metrics=[keras.metrics.CategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "modeldir = \"./logs/malaria/linear-8192-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_svm.fit(\n",
    "    prepare(ds_train_normalized),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=prepare(ds_test_normalized),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=modeldir + \"/log\",\n",
    "            histogram_freq=1,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "model_svm.save(modeldir + \"/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_samples(psi, t=1000):\n",
    "    return [\n",
    "        list(\n",
    "            ds_train_raw.shuffle(n)\n",
    "            .take(psi)\n",
    "            .map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(psi)\n",
    "            .as_numpy_iterator()\n",
    "        )[0][0]\n",
    "        for _ in range(t)\n",
    "    ]\n",
    "\n",
    "\n",
    "def _tf_ann(X, samples, p=2, soft=True):\n",
    "    m_dis = None\n",
    "    for i in range(samples.shape[0]):\n",
    "        i_sample = samples[i : i + 1, :]\n",
    "        l_dis = tf.math.reduce_sum((X - i_sample) ** p, axis=1, keepdims=True) ** (\n",
    "            1 / p\n",
    "        )\n",
    "        if m_dis is None:\n",
    "            m_dis = l_dis\n",
    "        else:\n",
    "            m_dis = tf.concat([m_dis, l_dis], 1)\n",
    "\n",
    "    if soft:\n",
    "        feature_map = tf.nn.softmax(-m_dis, axis=0)\n",
    "    else:\n",
    "        feature_map = tf.one_hot(tf.math.argmax(-m_dis, axis=1), samples.shape[0])\n",
    "    # l_dis_min = tf.math.reduce_sum(m_dis * feature_map, axis=0)\n",
    "    return feature_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolationEncodingLayer(layers.Layer):\n",
    "    def __init__(self, samples, p=2, soft=True, **kwargs):\n",
    "        super(IsolationEncodingLayer, self).__init__(**kwargs)\n",
    "        self.samples = samples\n",
    "        self.p = p\n",
    "        self.soft = soft\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return _tf_ann(inputs, self.samples, self.p, self.soft)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"samples\": self.samples,\n",
    "                \"p\": self.p,\n",
    "                \"soft\": self.soft,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "def build_model(t_samples, p=2, soft=True):\n",
    "    t = len(t_samples)\n",
    "    if t <= 0:\n",
    "        raise ValueError(\"t <= 0\")\n",
    "    _, dims = t_samples[0].shape\n",
    "\n",
    "    inputs = keras.Input(name=\"inputs_x\", shape=(dims,))\n",
    "    lambdas = [\n",
    "        IsolationEncodingLayer(t_samples[i], p=p, soft=soft, name=\"ann_{}\".format(i))(\n",
    "            inputs\n",
    "        )\n",
    "        for i in range(t)\n",
    "    ]\n",
    "    concatenated = layers.Concatenate(axis=1, name=\"concatenated\")(lambdas)\n",
    "    outputs = layers.Dense(units=n_classes, name=\"outputs_y\")(concatenated)\n",
    "\n",
    "    model = keras.Model(name=\"isolation_encoding\", inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=keras.losses.hinge,\n",
    "        metrics=[keras.metrics.CategoricalAccuracy(name=\"acc\")],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleIsolationEncodingLayer(layers.Layer):\n",
    "    def __init__(self, samples, p=2, **kwargs):\n",
    "        super(FlexibleIsolationEncodingLayer, self).__init__(**kwargs)\n",
    "        self.samples = samples\n",
    "        self.p = p\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.dimential_weights = self.add_weight(\n",
    "            name=\"dimential_weights\",\n",
    "            shape=(\n",
    "                1,\n",
    "                self.samples.shape[0],\n",
    "            ),\n",
    "            initializer=\"ones\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        super(FlexibleIsolationEncodingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return _tf_ann(inputs, self.samples, self.p) * self.dimential_weights\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"samples\": self.samples,\n",
    "                \"p\": self.p,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "def build_flex_model(t_samples, p=2):\n",
    "    t = len(t_samples)\n",
    "    if t <= 0:\n",
    "        raise ValueError(\"t <= 0\")\n",
    "    _, dims = t_samples[0].shape\n",
    "\n",
    "    inputs = keras.Input(name=\"inputs_x\", shape=(dims,))\n",
    "    lambdas = [\n",
    "        FlexibleIsolationEncodingLayer(t_samples[i], p=p, name=\"ann_flex_{}\".format(i))(\n",
    "            inputs\n",
    "        )\n",
    "        for i in range(t)\n",
    "    ]\n",
    "    concatenated = layers.Concatenate(axis=1, name=\"concatenated\")(lambdas)\n",
    "    outputs = layers.Dense(units=n_classes, name=\"outputs_y\")(concatenated)\n",
    "\n",
    "    model = keras.Model(name=\"isolation_encoding\", inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=keras.losses.hinge,\n",
    "        metrics=[keras.metrics.CategoricalAccuracy(name=\"acc\")],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "345/345 [==============================] - 68s 157ms/step - loss: 0.8039 - acc: 0.6350 - val_loss: 0.7641 - val_acc: 0.6468\n",
      "Epoch 2/30\n",
      "345/345 [==============================] - 45s 131ms/step - loss: 0.7487 - acc: 0.6569 - val_loss: 0.7522 - val_acc: 0.6548\n",
      "Epoch 3/30\n",
      "345/345 [==============================] - 45s 131ms/step - loss: 0.7338 - acc: 0.6629 - val_loss: 0.7477 - val_acc: 0.6584\n",
      "Epoch 4/30\n",
      "345/345 [==============================] - 45s 131ms/step - loss: 0.7254 - acc: 0.6667 - val_loss: 0.7462 - val_acc: 0.6584\n",
      "Epoch 5/30\n",
      "345/345 [==============================] - 45s 131ms/step - loss: 0.7185 - acc: 0.6702 - val_loss: 0.7447 - val_acc: 0.6606\n",
      "Epoch 6/30\n",
      "345/345 [==============================] - 45s 132ms/step - loss: 0.7142 - acc: 0.6737 - val_loss: 0.7469 - val_acc: 0.6597\n",
      "Epoch 7/30\n",
      "345/345 [==============================] - 45s 131ms/step - loss: 0.7112 - acc: 0.6756 - val_loss: 0.7467 - val_acc: 0.6607\n",
      "Epoch 8/30\n",
      "345/345 [==============================] - 45s 131ms/step - loss: 0.7077 - acc: 0.6785 - val_loss: 0.7493 - val_acc: 0.6611\n",
      "Epoch 9/30\n",
      "345/345 [==============================] - 47s 136ms/step - loss: 0.7060 - acc: 0.6793 - val_loss: 0.7491 - val_acc: 0.6615\n",
      "Epoch 10/30\n",
      "345/345 [==============================] - 47s 135ms/step - loss: 0.7040 - acc: 0.6805 - val_loss: 0.7503 - val_acc: 0.6618\n",
      "Epoch 11/30\n",
      "345/345 [==============================] - 45s 131ms/step - loss: 0.7020 - acc: 0.6819 - val_loss: 0.7539 - val_acc: 0.6597\n",
      "Epoch 12/30\n",
      "345/345 [==============================] - 45s 131ms/step - loss: 0.7010 - acc: 0.6843 - val_loss: 0.7518 - val_acc: 0.6624\n",
      "Epoch 13/30\n",
      "345/345 [==============================] - 45s 131ms/step - loss: 0.6998 - acc: 0.6844 - val_loss: 0.7540 - val_acc: 0.6577\n",
      "Epoch 14/30\n",
      "345/345 [==============================] - 46s 132ms/step - loss: 0.6988 - acc: 0.6864 - val_loss: 0.7545 - val_acc: 0.6606\n",
      "Epoch 15/30\n",
      "345/345 [==============================] - 46s 132ms/step - loss: 0.6976 - acc: 0.6868 - val_loss: 0.7559 - val_acc: 0.6577\n",
      "Epoch 16/30\n",
      "345/345 [==============================] - 46s 132ms/step - loss: 0.6972 - acc: 0.6880 - val_loss: 0.7559 - val_acc: 0.6577\n",
      "Epoch 17/30\n",
      "345/345 [==============================] - 47s 136ms/step - loss: 0.6965 - acc: 0.6882 - val_loss: 0.7563 - val_acc: 0.6589\n",
      "Epoch 18/30\n",
      "345/345 [==============================] - 46s 133ms/step - loss: 0.6959 - acc: 0.6883 - val_loss: 0.7556 - val_acc: 0.6597\n",
      "Epoch 19/30\n",
      "345/345 [==============================] - 47s 135ms/step - loss: 0.6957 - acc: 0.6894 - val_loss: 0.7578 - val_acc: 0.6566\n",
      "Epoch 20/30\n",
      "345/345 [==============================] - 46s 134ms/step - loss: 0.6953 - acc: 0.6887 - val_loss: 0.7583 - val_acc: 0.6524\n",
      "Epoch 21/30\n",
      "345/345 [==============================] - 46s 133ms/step - loss: 0.6948 - acc: 0.6912 - val_loss: 0.7595 - val_acc: 0.6533\n",
      "Epoch 22/30\n",
      "345/345 [==============================] - 47s 135ms/step - loss: 0.6944 - acc: 0.6899 - val_loss: 0.7614 - val_acc: 0.6571\n",
      "Epoch 23/30\n",
      "345/345 [==============================] - 46s 134ms/step - loss: 0.6936 - acc: 0.6906 - val_loss: 0.7599 - val_acc: 0.6578\n",
      "Epoch 24/30\n",
      "345/345 [==============================] - 46s 134ms/step - loss: 0.6939 - acc: 0.6911 - val_loss: 0.7608 - val_acc: 0.6533\n",
      "Epoch 25/30\n",
      "345/345 [==============================] - 46s 134ms/step - loss: 0.6939 - acc: 0.6906 - val_loss: 0.7621 - val_acc: 0.6538\n",
      "Epoch 26/30\n",
      "345/345 [==============================] - 45s 131ms/step - loss: 0.6933 - acc: 0.6906 - val_loss: 0.7622 - val_acc: 0.6504\n",
      "Epoch 27/30\n",
      "345/345 [==============================] - 45s 131ms/step - loss: 0.6932 - acc: 0.6898 - val_loss: 0.7622 - val_acc: 0.6546\n",
      "Epoch 28/30\n",
      "345/345 [==============================] - 56s 161ms/step - loss: 0.6927 - acc: 0.6906 - val_loss: 0.7619 - val_acc: 0.6537\n",
      "Epoch 29/30\n",
      "345/345 [==============================] - 46s 134ms/step - loss: 0.6927 - acc: 0.6917 - val_loss: 0.7617 - val_acc: 0.6549\n",
      "Epoch 30/30\n",
      "345/345 [==============================] - 46s 132ms/step - loss: 0.6933 - acc: 0.6906 - val_loss: 0.7641 - val_acc: 0.6544\n",
      "INFO:tensorflow:Assets written to: ./logs/malaria/hard-20x50-20230309-215805/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/malaria/hard-20x50-20230309-215805/model\\assets\n"
     ]
    }
   ],
   "source": [
    "t_samples = gen_samples(psi=20, t=50)\n",
    "\n",
    "\n",
    "model_hard_20_50 = build_model(t_samples, soft=False)\n",
    "modeldir = \"./logs/malaria/hard-20x50-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_hard_20_50.fit(\n",
    "    prepare(ds_train_normalized),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=prepare(ds_test_normalized),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(log_dir=modeldir + \"/log\", histogram_freq=1)\n",
    "    ],\n",
    ")\n",
    "model_hard_20_50.save(modeldir + \"/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "345/345 [==============================] - 74s 167ms/step - loss: 0.8604 - acc: 0.6060 - val_loss: 0.7927 - val_acc: 0.6526\n",
      "Epoch 2/30\n",
      "345/345 [==============================] - 48s 139ms/step - loss: 0.7830 - acc: 0.6515 - val_loss: 0.7641 - val_acc: 0.6557\n",
      "Epoch 3/30\n",
      "345/345 [==============================] - 48s 138ms/step - loss: 0.7621 - acc: 0.6571 - val_loss: 0.7486 - val_acc: 0.6607\n",
      "Epoch 4/30\n",
      "345/345 [==============================] - 47s 136ms/step - loss: 0.7491 - acc: 0.6640 - val_loss: 0.7375 - val_acc: 0.6629\n",
      "Epoch 5/30\n",
      "345/345 [==============================] - 47s 137ms/step - loss: 0.7425 - acc: 0.6653 - val_loss: 0.7339 - val_acc: 0.6678\n",
      "Epoch 6/30\n",
      "345/345 [==============================] - 48s 139ms/step - loss: 0.7333 - acc: 0.6693 - val_loss: 0.7339 - val_acc: 0.6685\n",
      "Epoch 7/30\n",
      "345/345 [==============================] - 49s 141ms/step - loss: 0.7266 - acc: 0.6723 - val_loss: 0.7268 - val_acc: 0.6707\n",
      "Epoch 8/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.7217 - acc: 0.6725 - val_loss: 0.7228 - val_acc: 0.6714\n",
      "Epoch 9/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7157 - acc: 0.6750 - val_loss: 0.7143 - val_acc: 0.6729\n",
      "Epoch 10/30\n",
      "345/345 [==============================] - 49s 142ms/step - loss: 0.7136 - acc: 0.6737 - val_loss: 0.7106 - val_acc: 0.6758\n",
      "Epoch 11/30\n",
      "345/345 [==============================] - 51s 147ms/step - loss: 0.7083 - acc: 0.6788 - val_loss: 0.7080 - val_acc: 0.6780\n",
      "Epoch 12/30\n",
      "345/345 [==============================] - 50s 146ms/step - loss: 0.7073 - acc: 0.6796 - val_loss: 0.7096 - val_acc: 0.6758\n",
      "Epoch 13/30\n",
      "345/345 [==============================] - 51s 149ms/step - loss: 0.7051 - acc: 0.6758 - val_loss: 0.7101 - val_acc: 0.6785\n",
      "Epoch 14/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.7004 - acc: 0.6781 - val_loss: 0.7066 - val_acc: 0.6736\n",
      "Epoch 15/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.7006 - acc: 0.6802 - val_loss: 0.7085 - val_acc: 0.6745\n",
      "Epoch 16/30\n",
      "345/345 [==============================] - 49s 144ms/step - loss: 0.6982 - acc: 0.6806 - val_loss: 0.6992 - val_acc: 0.6818\n",
      "Epoch 17/30\n",
      "345/345 [==============================] - 51s 148ms/step - loss: 0.6973 - acc: 0.6801 - val_loss: 0.6999 - val_acc: 0.6798\n",
      "Epoch 18/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.6973 - acc: 0.6816 - val_loss: 0.6978 - val_acc: 0.6803\n",
      "Epoch 19/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6941 - acc: 0.6816 - val_loss: 0.7014 - val_acc: 0.6807\n",
      "Epoch 20/30\n",
      "345/345 [==============================] - 50s 146ms/step - loss: 0.6929 - acc: 0.6848 - val_loss: 0.6967 - val_acc: 0.6789\n",
      "Epoch 21/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.6939 - acc: 0.6819 - val_loss: 0.6981 - val_acc: 0.6774\n",
      "Epoch 22/30\n",
      "345/345 [==============================] - 51s 148ms/step - loss: 0.6900 - acc: 0.6848 - val_loss: 0.7009 - val_acc: 0.6800\n",
      "Epoch 23/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.6907 - acc: 0.6841 - val_loss: 0.7014 - val_acc: 0.6785\n",
      "Epoch 24/30\n",
      "345/345 [==============================] - 49s 142ms/step - loss: 0.6907 - acc: 0.6847 - val_loss: 0.6972 - val_acc: 0.6785\n",
      "Epoch 25/30\n",
      "345/345 [==============================] - 51s 147ms/step - loss: 0.6864 - acc: 0.6875 - val_loss: 0.6943 - val_acc: 0.6807\n",
      "Epoch 26/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.6872 - acc: 0.6848 - val_loss: 0.6932 - val_acc: 0.6831\n",
      "Epoch 27/30\n",
      "345/345 [==============================] - 49s 141ms/step - loss: 0.6867 - acc: 0.6891 - val_loss: 0.6997 - val_acc: 0.6791\n",
      "Epoch 28/30\n",
      "345/345 [==============================] - 49s 142ms/step - loss: 0.6860 - acc: 0.6856 - val_loss: 0.6993 - val_acc: 0.6785\n",
      "Epoch 29/30\n",
      "345/345 [==============================] - 49s 142ms/step - loss: 0.6828 - acc: 0.6883 - val_loss: 0.6992 - val_acc: 0.6812\n",
      "Epoch 30/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6815 - acc: 0.6896 - val_loss: 0.6927 - val_acc: 0.6851\n",
      "INFO:tensorflow:Assets written to: ./logs/malaria/soft-20x50-20230309-222224/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/malaria/soft-20x50-20230309-222224/model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_soft_20_50 = build_model(t_samples, soft=True)\n",
    "modeldir = \"./logs/malaria/soft-20x50-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_soft_20_50.fit(\n",
    "    prepare(ds_train_normalized),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=prepare(ds_test_normalized),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(log_dir=modeldir + \"/log\", histogram_freq=1)\n",
    "    ],\n",
    ")\n",
    "model_soft_20_50.save(modeldir + \"/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "345/345 [==============================] - 79s 176ms/step - loss: 0.8524 - acc: 0.6109 - val_loss: 0.7876 - val_acc: 0.6511\n",
      "Epoch 2/30\n",
      "345/345 [==============================] - 50s 146ms/step - loss: 0.7765 - acc: 0.6531 - val_loss: 0.7592 - val_acc: 0.6598\n",
      "Epoch 3/30\n",
      "345/345 [==============================] - 50s 146ms/step - loss: 0.7584 - acc: 0.6612 - val_loss: 0.7485 - val_acc: 0.6646\n",
      "Epoch 4/30\n",
      "345/345 [==============================] - 51s 147ms/step - loss: 0.7452 - acc: 0.6650 - val_loss: 0.7361 - val_acc: 0.6676\n",
      "Epoch 5/30\n",
      "345/345 [==============================] - 51s 148ms/step - loss: 0.7371 - acc: 0.6664 - val_loss: 0.7293 - val_acc: 0.6664\n",
      "Epoch 6/30\n",
      "345/345 [==============================] - 51s 148ms/step - loss: 0.7279 - acc: 0.6708 - val_loss: 0.7195 - val_acc: 0.6696\n",
      "Epoch 7/30\n",
      "345/345 [==============================] - 51s 147ms/step - loss: 0.7213 - acc: 0.6725 - val_loss: 0.7154 - val_acc: 0.6749\n",
      "Epoch 8/30\n",
      "345/345 [==============================] - 51s 148ms/step - loss: 0.7138 - acc: 0.6768 - val_loss: 0.7116 - val_acc: 0.6776\n",
      "Epoch 9/30\n",
      "345/345 [==============================] - 52s 151ms/step - loss: 0.7091 - acc: 0.6768 - val_loss: 0.7129 - val_acc: 0.6734\n",
      "Epoch 10/30\n",
      "345/345 [==============================] - 52s 151ms/step - loss: 0.7067 - acc: 0.6783 - val_loss: 0.7090 - val_acc: 0.6745\n",
      "Epoch 11/30\n",
      "345/345 [==============================] - 51s 147ms/step - loss: 0.7050 - acc: 0.6763 - val_loss: 0.7084 - val_acc: 0.6687\n",
      "Epoch 12/30\n",
      "345/345 [==============================] - 51s 149ms/step - loss: 0.6979 - acc: 0.6823 - val_loss: 0.7034 - val_acc: 0.6771\n",
      "Epoch 13/30\n",
      "345/345 [==============================] - 51s 148ms/step - loss: 0.6962 - acc: 0.6819 - val_loss: 0.7048 - val_acc: 0.6760\n",
      "Epoch 14/30\n",
      "345/345 [==============================] - 50s 146ms/step - loss: 0.6906 - acc: 0.6838 - val_loss: 0.7048 - val_acc: 0.6820\n",
      "Epoch 15/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6911 - acc: 0.6858 - val_loss: 0.6973 - val_acc: 0.6827\n",
      "Epoch 16/30\n",
      "345/345 [==============================] - 50s 146ms/step - loss: 0.6892 - acc: 0.6855 - val_loss: 0.6999 - val_acc: 0.6798\n",
      "Epoch 17/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.6900 - acc: 0.6845 - val_loss: 0.6925 - val_acc: 0.6825\n",
      "Epoch 18/30\n",
      "345/345 [==============================] - 53s 152ms/step - loss: 0.6865 - acc: 0.6869 - val_loss: 0.6941 - val_acc: 0.6851\n",
      "Epoch 19/30\n",
      "345/345 [==============================] - 50s 146ms/step - loss: 0.6838 - acc: 0.6859 - val_loss: 0.7013 - val_acc: 0.6776\n",
      "Epoch 20/30\n",
      "345/345 [==============================] - 50s 146ms/step - loss: 0.6843 - acc: 0.6859 - val_loss: 0.6973 - val_acc: 0.6787\n",
      "Epoch 21/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6791 - acc: 0.6891 - val_loss: 0.6932 - val_acc: 0.6841\n",
      "Epoch 22/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6842 - acc: 0.6863 - val_loss: 0.6923 - val_acc: 0.6823\n",
      "Epoch 23/30\n",
      "345/345 [==============================] - 51s 148ms/step - loss: 0.6801 - acc: 0.6876 - val_loss: 0.6908 - val_acc: 0.6851\n",
      "Epoch 24/30\n",
      "345/345 [==============================] - 52s 150ms/step - loss: 0.6771 - acc: 0.6898 - val_loss: 0.6868 - val_acc: 0.6870\n",
      "Epoch 25/30\n",
      "345/345 [==============================] - 51s 147ms/step - loss: 0.6782 - acc: 0.6915 - val_loss: 0.6842 - val_acc: 0.6887\n",
      "Epoch 26/30\n",
      "345/345 [==============================] - 50s 146ms/step - loss: 0.6778 - acc: 0.6917 - val_loss: 0.6917 - val_acc: 0.6827\n",
      "Epoch 27/30\n",
      "345/345 [==============================] - 51s 148ms/step - loss: 0.6768 - acc: 0.6906 - val_loss: 0.6943 - val_acc: 0.6802\n",
      "Epoch 28/30\n",
      "345/345 [==============================] - 52s 150ms/step - loss: 0.6732 - acc: 0.6919 - val_loss: 0.6902 - val_acc: 0.6780\n",
      "Epoch 29/30\n",
      "345/345 [==============================] - 51s 149ms/step - loss: 0.6764 - acc: 0.6908 - val_loss: 0.6949 - val_acc: 0.6820\n",
      "Epoch 30/30\n",
      "345/345 [==============================] - 52s 150ms/step - loss: 0.6746 - acc: 0.6920 - val_loss: 0.6861 - val_acc: 0.6860\n",
      "INFO:tensorflow:Assets written to: ./logs/malaria/flex-20x50-20230309-224828/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/malaria/flex-20x50-20230309-224828/model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_flex_20_50 = build_flex_model(t_samples)\n",
    "# model_flex_20_50.summary()\n",
    "modeldir = \"./logs/malaria/flex-20x50-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_flex_20_50.fit(\n",
    "    prepare(ds_train_normalized),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=prepare(ds_test_normalized),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(log_dir=modeldir + \"/log\", histogram_freq=1)\n",
    "    ],\n",
    ")\n",
    "model_flex_20_50.save(modeldir + \"/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "345/345 [==============================] - 59s 131ms/step - loss: 0.8968 - acc: 0.6161 - val_loss: 0.8151 - val_acc: 0.6321\n",
      "Epoch 2/30\n",
      "345/345 [==============================] - 37s 108ms/step - loss: 0.7864 - acc: 0.6374 - val_loss: 0.7774 - val_acc: 0.6353\n",
      "Epoch 3/30\n",
      "345/345 [==============================] - 39s 113ms/step - loss: 0.7628 - acc: 0.6427 - val_loss: 0.7681 - val_acc: 0.6410\n",
      "Epoch 4/30\n",
      "345/345 [==============================] - 40s 115ms/step - loss: 0.7526 - acc: 0.6482 - val_loss: 0.7633 - val_acc: 0.6444\n",
      "Epoch 5/30\n",
      "345/345 [==============================] - 40s 116ms/step - loss: 0.7460 - acc: 0.6516 - val_loss: 0.7604 - val_acc: 0.6455\n",
      "Epoch 6/30\n",
      "345/345 [==============================] - 39s 112ms/step - loss: 0.7408 - acc: 0.6546 - val_loss: 0.7591 - val_acc: 0.6455\n",
      "Epoch 7/30\n",
      "345/345 [==============================] - 39s 112ms/step - loss: 0.7372 - acc: 0.6570 - val_loss: 0.7580 - val_acc: 0.6462\n",
      "Epoch 8/30\n",
      "345/345 [==============================] - 39s 112ms/step - loss: 0.7341 - acc: 0.6591 - val_loss: 0.7575 - val_acc: 0.6453\n",
      "Epoch 9/30\n",
      "345/345 [==============================] - 39s 113ms/step - loss: 0.7317 - acc: 0.6610 - val_loss: 0.7575 - val_acc: 0.6444\n",
      "Epoch 10/30\n",
      "345/345 [==============================] - 39s 113ms/step - loss: 0.7295 - acc: 0.6617 - val_loss: 0.7574 - val_acc: 0.6455\n",
      "Epoch 11/30\n",
      "345/345 [==============================] - 40s 114ms/step - loss: 0.7278 - acc: 0.6637 - val_loss: 0.7580 - val_acc: 0.6482\n",
      "Epoch 12/30\n",
      "345/345 [==============================] - 40s 116ms/step - loss: 0.7263 - acc: 0.6647 - val_loss: 0.7583 - val_acc: 0.6464\n",
      "Epoch 13/30\n",
      "345/345 [==============================] - 41s 118ms/step - loss: 0.7249 - acc: 0.6667 - val_loss: 0.7588 - val_acc: 0.6497\n",
      "Epoch 14/30\n",
      "345/345 [==============================] - 40s 117ms/step - loss: 0.7236 - acc: 0.6682 - val_loss: 0.7593 - val_acc: 0.6499\n",
      "Epoch 15/30\n",
      "345/345 [==============================] - 40s 115ms/step - loss: 0.7227 - acc: 0.6683 - val_loss: 0.7595 - val_acc: 0.6502\n",
      "Epoch 16/30\n",
      "345/345 [==============================] - 40s 117ms/step - loss: 0.7217 - acc: 0.6689 - val_loss: 0.7596 - val_acc: 0.6513\n",
      "Epoch 17/30\n",
      "345/345 [==============================] - 40s 115ms/step - loss: 0.7208 - acc: 0.6690 - val_loss: 0.7600 - val_acc: 0.6499\n",
      "Epoch 18/30\n",
      "345/345 [==============================] - 40s 117ms/step - loss: 0.7199 - acc: 0.6705 - val_loss: 0.7601 - val_acc: 0.6500\n",
      "Epoch 19/30\n",
      "345/345 [==============================] - 41s 118ms/step - loss: 0.7193 - acc: 0.6712 - val_loss: 0.7611 - val_acc: 0.6515\n",
      "Epoch 20/30\n",
      "345/345 [==============================] - 41s 119ms/step - loss: 0.7185 - acc: 0.6699 - val_loss: 0.7615 - val_acc: 0.6515\n",
      "Epoch 21/30\n",
      "345/345 [==============================] - 40s 116ms/step - loss: 0.7179 - acc: 0.6712 - val_loss: 0.7622 - val_acc: 0.6520\n",
      "Epoch 22/30\n",
      "345/345 [==============================] - 40s 115ms/step - loss: 0.7175 - acc: 0.6711 - val_loss: 0.7623 - val_acc: 0.6517\n",
      "Epoch 23/30\n",
      "345/345 [==============================] - 41s 118ms/step - loss: 0.7168 - acc: 0.6713 - val_loss: 0.7625 - val_acc: 0.6517\n",
      "Epoch 24/30\n",
      "345/345 [==============================] - 90s 261ms/step - loss: 0.7164 - acc: 0.6716 - val_loss: 0.7627 - val_acc: 0.6515\n",
      "Epoch 25/30\n",
      "345/345 [==============================] - 41s 120ms/step - loss: 0.7162 - acc: 0.6730 - val_loss: 0.7633 - val_acc: 0.6504\n",
      "Epoch 26/30\n",
      "345/345 [==============================] - 40s 115ms/step - loss: 0.7157 - acc: 0.6720 - val_loss: 0.7634 - val_acc: 0.6499\n",
      "Epoch 27/30\n",
      "345/345 [==============================] - 40s 115ms/step - loss: 0.7152 - acc: 0.6730 - val_loss: 0.7637 - val_acc: 0.6495\n",
      "Epoch 28/30\n",
      "345/345 [==============================] - 39s 113ms/step - loss: 0.7149 - acc: 0.6732 - val_loss: 0.7643 - val_acc: 0.6486\n",
      "Epoch 29/30\n",
      "345/345 [==============================] - 38s 111ms/step - loss: 0.7146 - acc: 0.6733 - val_loss: 0.7644 - val_acc: 0.6495\n",
      "Epoch 30/30\n",
      "345/345 [==============================] - 38s 111ms/step - loss: 0.7143 - acc: 0.6735 - val_loss: 0.7647 - val_acc: 0.6493\n",
      "INFO:tensorflow:Assets written to: ./logs/malaria/hard-100x10-20230309-231626/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/malaria/hard-100x10-20230309-231626/model\\assets\n"
     ]
    }
   ],
   "source": [
    "t_samples = gen_samples(psi=100, t=10)\n",
    "\n",
    "model_hard_100_10 = build_model(t_samples, soft=False)\n",
    "modeldir = \"./logs/malaria/hard-100x10-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_hard_100_10.fit(\n",
    "    prepare(ds_train_normalized),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=prepare(ds_test_normalized),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(log_dir=modeldir + \"/log\", histogram_freq=1)\n",
    "    ],\n",
    ")\n",
    "model_hard_100_10.save(modeldir + \"/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "345/345 [==============================] - 75s 176ms/step - loss: 0.8601 - acc: 0.6118 - val_loss: 0.7969 - val_acc: 0.6528\n",
      "Epoch 2/30\n",
      "345/345 [==============================] - 52s 150ms/step - loss: 0.7839 - acc: 0.6514 - val_loss: 0.7610 - val_acc: 0.6618\n",
      "Epoch 3/30\n",
      "345/345 [==============================] - 51s 147ms/step - loss: 0.7645 - acc: 0.6600 - val_loss: 0.7526 - val_acc: 0.6635\n",
      "Epoch 4/30\n",
      "345/345 [==============================] - 51s 147ms/step - loss: 0.7516 - acc: 0.6653 - val_loss: 0.7403 - val_acc: 0.6687\n",
      "Epoch 5/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7406 - acc: 0.6672 - val_loss: 0.7296 - val_acc: 0.6680\n",
      "Epoch 6/30\n",
      "345/345 [==============================] - 49s 142ms/step - loss: 0.7333 - acc: 0.6682 - val_loss: 0.7242 - val_acc: 0.6731\n",
      "Epoch 7/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.7272 - acc: 0.6709 - val_loss: 0.7227 - val_acc: 0.6700\n",
      "Epoch 8/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7218 - acc: 0.6717 - val_loss: 0.7163 - val_acc: 0.6736\n",
      "Epoch 9/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7187 - acc: 0.6731 - val_loss: 0.7095 - val_acc: 0.6765\n",
      "Epoch 10/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7140 - acc: 0.6740 - val_loss: 0.7076 - val_acc: 0.6753\n",
      "Epoch 11/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7098 - acc: 0.6743 - val_loss: 0.7159 - val_acc: 0.6749\n",
      "Epoch 12/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.7084 - acc: 0.6761 - val_loss: 0.7058 - val_acc: 0.6772\n",
      "Epoch 13/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7027 - acc: 0.6778 - val_loss: 0.7056 - val_acc: 0.6763\n",
      "Epoch 14/30\n",
      "345/345 [==============================] - 49s 142ms/step - loss: 0.7032 - acc: 0.6782 - val_loss: 0.7031 - val_acc: 0.6800\n",
      "Epoch 15/30\n",
      "345/345 [==============================] - 49s 142ms/step - loss: 0.7012 - acc: 0.6799 - val_loss: 0.7007 - val_acc: 0.6840\n",
      "Epoch 16/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7000 - acc: 0.6804 - val_loss: 0.7084 - val_acc: 0.6811\n",
      "Epoch 17/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.6983 - acc: 0.6789 - val_loss: 0.7052 - val_acc: 0.6772\n",
      "Epoch 18/30\n",
      "345/345 [==============================] - 49s 142ms/step - loss: 0.6967 - acc: 0.6808 - val_loss: 0.6989 - val_acc: 0.6825\n",
      "Epoch 19/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.6950 - acc: 0.6831 - val_loss: 0.6939 - val_acc: 0.6827\n",
      "Epoch 20/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.6939 - acc: 0.6836 - val_loss: 0.6953 - val_acc: 0.6838\n",
      "Epoch 21/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.6957 - acc: 0.6823 - val_loss: 0.6985 - val_acc: 0.6849\n",
      "Epoch 22/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6924 - acc: 0.6836 - val_loss: 0.6980 - val_acc: 0.6851\n",
      "Epoch 23/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.6924 - acc: 0.6839 - val_loss: 0.6978 - val_acc: 0.6816\n",
      "Epoch 24/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6893 - acc: 0.6850 - val_loss: 0.6916 - val_acc: 0.6832\n",
      "Epoch 25/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6887 - acc: 0.6842 - val_loss: 0.6952 - val_acc: 0.6800\n",
      "Epoch 26/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.6868 - acc: 0.6865 - val_loss: 0.6941 - val_acc: 0.6792\n",
      "Epoch 27/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6877 - acc: 0.6856 - val_loss: 0.6950 - val_acc: 0.6802\n",
      "Epoch 28/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6875 - acc: 0.6859 - val_loss: 0.6954 - val_acc: 0.6840\n",
      "Epoch 29/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6873 - acc: 0.6860 - val_loss: 0.6920 - val_acc: 0.6867\n",
      "Epoch 30/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6847 - acc: 0.6886 - val_loss: 0.6923 - val_acc: 0.6849\n",
      "INFO:tensorflow:Assets written to: ./logs/malaria/soft-100x10-20230309-233820/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/malaria/soft-100x10-20230309-233820/model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_soft_100_10 = build_model(t_samples, soft=True)\n",
    "modeldir = \"./logs/malaria/soft-100x10-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_soft_100_10.fit(\n",
    "    prepare(ds_train_normalized),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=prepare(ds_test_normalized),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(log_dir=modeldir + \"/log\", histogram_freq=1)\n",
    "    ],\n",
    ")\n",
    "model_soft_100_10.save(modeldir + \"/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "345/345 [==============================] - 71s 166ms/step - loss: 0.8544 - acc: 0.6048 - val_loss: 0.7830 - val_acc: 0.6586\n",
      "Epoch 2/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7780 - acc: 0.6530 - val_loss: 0.7587 - val_acc: 0.6609\n",
      "Epoch 3/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.7588 - acc: 0.6603 - val_loss: 0.7426 - val_acc: 0.6651\n",
      "Epoch 4/30\n",
      "345/345 [==============================] - 49s 142ms/step - loss: 0.7438 - acc: 0.6658 - val_loss: 0.7371 - val_acc: 0.6649\n",
      "Epoch 5/30\n",
      "345/345 [==============================] - 49s 142ms/step - loss: 0.7348 - acc: 0.6665 - val_loss: 0.7365 - val_acc: 0.6615\n",
      "Epoch 6/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7258 - acc: 0.6709 - val_loss: 0.7195 - val_acc: 0.6763\n",
      "Epoch 7/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7208 - acc: 0.6714 - val_loss: 0.7181 - val_acc: 0.6794\n",
      "Epoch 8/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.7140 - acc: 0.6728 - val_loss: 0.7078 - val_acc: 0.6811\n",
      "Epoch 9/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.7106 - acc: 0.6760 - val_loss: 0.7088 - val_acc: 0.6745\n",
      "Epoch 10/30\n",
      "345/345 [==============================] - 49s 142ms/step - loss: 0.7048 - acc: 0.6796 - val_loss: 0.6992 - val_acc: 0.6807\n",
      "Epoch 11/30\n",
      "345/345 [==============================] - 49s 144ms/step - loss: 0.6997 - acc: 0.6818 - val_loss: 0.7055 - val_acc: 0.6760\n",
      "Epoch 12/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6974 - acc: 0.6810 - val_loss: 0.7006 - val_acc: 0.6729\n",
      "Epoch 13/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6956 - acc: 0.6830 - val_loss: 0.6985 - val_acc: 0.6783\n",
      "Epoch 14/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6944 - acc: 0.6830 - val_loss: 0.6931 - val_acc: 0.6827\n",
      "Epoch 15/30\n",
      "345/345 [==============================] - 50s 146ms/step - loss: 0.6923 - acc: 0.6836 - val_loss: 0.7038 - val_acc: 0.6823\n",
      "Epoch 16/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6884 - acc: 0.6855 - val_loss: 0.6908 - val_acc: 0.6820\n",
      "Epoch 17/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.6883 - acc: 0.6848 - val_loss: 0.6979 - val_acc: 0.6809\n",
      "Epoch 18/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6875 - acc: 0.6861 - val_loss: 0.6924 - val_acc: 0.6823\n",
      "Epoch 19/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.6857 - acc: 0.6857 - val_loss: 0.6901 - val_acc: 0.6867\n",
      "Epoch 20/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.6821 - acc: 0.6887 - val_loss: 0.6925 - val_acc: 0.6831\n",
      "Epoch 21/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6848 - acc: 0.6859 - val_loss: 0.6922 - val_acc: 0.6840\n",
      "Epoch 22/30\n",
      "345/345 [==============================] - 50s 145ms/step - loss: 0.6814 - acc: 0.6873 - val_loss: 0.6926 - val_acc: 0.6878\n",
      "Epoch 23/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6804 - acc: 0.6906 - val_loss: 0.6950 - val_acc: 0.6856\n",
      "Epoch 24/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6780 - acc: 0.6901 - val_loss: 0.6857 - val_acc: 0.6881\n",
      "Epoch 25/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6781 - acc: 0.6905 - val_loss: 0.6888 - val_acc: 0.6867\n",
      "Epoch 26/30\n",
      "345/345 [==============================] - 49s 143ms/step - loss: 0.6750 - acc: 0.6927 - val_loss: 0.6859 - val_acc: 0.6814\n",
      "Epoch 27/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6761 - acc: 0.6914 - val_loss: 0.6873 - val_acc: 0.6883\n",
      "Epoch 28/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6748 - acc: 0.6938 - val_loss: 0.6929 - val_acc: 0.6845\n",
      "Epoch 29/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6741 - acc: 0.6912 - val_loss: 0.6850 - val_acc: 0.6894\n",
      "Epoch 30/30\n",
      "345/345 [==============================] - 50s 144ms/step - loss: 0.6756 - acc: 0.6921 - val_loss: 0.6924 - val_acc: 0.6809\n",
      "INFO:tensorflow:Assets written to: ./logs/malaria/flex-100x10-20230310-000421/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./logs/malaria/flex-100x10-20230310-000421/model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_flex_100_10 = build_flex_model(t_samples)\n",
    "# model_flex_20_50.summary()\n",
    "modeldir = \"./logs/malaria/flex-100x10-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_flex_100_10.fit(\n",
    "    prepare(ds_train_normalized),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=prepare(ds_test_normalized),\n",
    "    callbacks=[\n",
    "        keras.callbacks.TensorBoard(log_dir=modeldir + \"/log\", histogram_freq=1)\n",
    "    ],\n",
    ")\n",
    "model_flex_100_10.save(modeldir + \"/model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a47f39fd070b48c46d7ad468a6f203b63097621f5a6c21be0934a2bf61a8c8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
