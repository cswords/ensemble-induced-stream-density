{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "image_w, image_h = 32, 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1], [-0.2], [-0.5], [-0.8]]\n",
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]], shape=(4, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.15000004]\n",
      " [-0.15000004]\n",
      " [-0.5       ]\n",
      " [-0.79999995]], shape=(4, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]], shape=(4, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.306981 ]\n",
      " [-0.306981 ]\n",
      " [-0.4750027]\n",
      " [-0.6255996]], shape=(4, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def soft_greater(x, y=0, resolution=2**32):\n",
    "    return (tf.math.tanh((x - y) * resolution) + 1.0) / 2.0\n",
    "\n",
    "def hard_encode(\n",
    "    x,  # n, dims\n",
    "    l_lower,  # psi, dims\n",
    "    l_upper,  # psi, dims\n",
    "):\n",
    "    x_encoded = tf.math.reduce_prod(\n",
    "        tf.cast(\n",
    "            tf.greater_equal(\n",
    "                tf.expand_dims(x, axis=1), tf.expand_dims(l_lower, axis=0)\n",
    "            ),\n",
    "            dtype=tf.float32,\n",
    "        ),\n",
    "        axis=2,\n",
    "    )\n",
    "    x_encoded *= tf.math.reduce_prod(\n",
    "        tf.cast(\n",
    "            tf.greater(tf.expand_dims(l_upper, axis=0), tf.expand_dims(x, axis=1)),\n",
    "            dtype=tf.float32,\n",
    "        ),\n",
    "        axis=2,\n",
    "    )\n",
    "\n",
    "    return x_encoded\n",
    "\n",
    "def hard_decode(\n",
    "    x_encoded,  # n, psi\n",
    "    l_lower,  # psi, dims\n",
    "    l_upper,  # psi, dims\n",
    "):\n",
    "    eps = tf.keras.backend.epsilon()\n",
    "    g_lower = tf.math.reduce_min(l_lower, axis=0, keepdims=True)\n",
    "    g_upper = tf.math.reduce_max(l_upper, axis=0, keepdims=True)\n",
    "\n",
    "    x_lower = tf.expand_dims(x_encoded, axis=2) * tf.expand_dims(\n",
    "        tf.math.add(l_lower, eps) - g_lower, axis=0\n",
    "    )\n",
    "    x_lower = (\n",
    "        tf.math.reduce_sum(\n",
    "            tf.one_hot(\n",
    "                tf.math.argmax(x_lower, axis=1),\n",
    "                x_encoded.shape[1],\n",
    "                axis=1,\n",
    "                dtype=tf.float32,\n",
    "            )\n",
    "            * x_lower,\n",
    "            axis=1,\n",
    "        )\n",
    "        - eps\n",
    "        + g_lower\n",
    "    )\n",
    "\n",
    "    x_upper = tf.expand_dims(x_encoded, axis=2) * tf.expand_dims(\n",
    "        tf.math.subtract(eps, l_upper) + g_upper, axis=0\n",
    "    )\n",
    "    x_upper = (\n",
    "        eps\n",
    "        + g_upper\n",
    "        - tf.math.reduce_sum(\n",
    "            tf.one_hot(\n",
    "                tf.math.argmax(x_upper, axis=1),\n",
    "                x_encoded.shape[1],\n",
    "                axis=1,\n",
    "                dtype=tf.float32,\n",
    "            )\n",
    "            * x_upper,\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "    return (x_lower + x_upper) / 2\n",
    "\n",
    "def soft_encode(\n",
    "    x,  # n, dims\n",
    "    l_lower,  # psi, dims\n",
    "    l_upper,  # psi, dims\n",
    "):\n",
    "    x_encoded = tf.math.reduce_prod(\n",
    "        soft_greater(tf.expand_dims(x, axis=1), tf.expand_dims(l_lower, axis=0)), axis=2\n",
    "    )\n",
    "    x_encoded *= tf.math.reduce_prod(\n",
    "        soft_greater(tf.expand_dims(l_upper, axis=0), tf.expand_dims(x, axis=1)), axis=2\n",
    "    )\n",
    "\n",
    "    return x_encoded\n",
    "\n",
    "def soft_decode(\n",
    "    x_encoded,  # n, psi\n",
    "    l_lower,  # psi, dims\n",
    "    l_upper,  # psi, dims\n",
    "):\n",
    "    eps = tf.keras.backend.epsilon()\n",
    "    g_lower = tf.math.reduce_min(l_lower, axis=0, keepdims=True)\n",
    "    g_upper = tf.math.reduce_max(l_upper, axis=0, keepdims=True)\n",
    "\n",
    "    x_lower = tf.expand_dims(x_encoded, axis=2) * tf.expand_dims(\n",
    "        tf.math.add(l_lower, eps) - g_lower, axis=0\n",
    "    )\n",
    "    x_lower = (\n",
    "        tf.math.reduce_sum(\n",
    "            tf.math.softmax(x_lower, axis=1) * x_lower,\n",
    "            axis=1,\n",
    "        )\n",
    "        - eps\n",
    "        + g_lower\n",
    "    )\n",
    "\n",
    "    x_upper = tf.expand_dims(x_encoded, axis=2) * tf.expand_dims(\n",
    "        tf.math.subtract(eps, l_upper) + g_upper, axis=0\n",
    "    )\n",
    "    x_upper = (\n",
    "        eps\n",
    "        + g_upper\n",
    "        - tf.math.reduce_sum(\n",
    "            tf.math.softmax(x_upper, axis=1) * x_upper,\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "    return (x_lower + x_upper) / 2\n",
    "\n",
    "x, l_lower, l_upper = (\n",
    "    [\n",
    "        [-0.1],\n",
    "        [-0.2],\n",
    "        [-0.5],\n",
    "        [-0.8],\n",
    "    ],\n",
    "    [\n",
    "        [-0.3],\n",
    "        [-0.6],\n",
    "        [-0.9],\n",
    "    ],\n",
    "    [\n",
    "        [0.0],\n",
    "        [-0.4],\n",
    "        [-0.7],\n",
    "    ],\n",
    ")\n",
    "\n",
    "x_encoded = hard_encode(x, l_lower, l_upper)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(x_encoded)\n",
    "print(hard_decode(x_encoded, l_lower, l_upper))\n",
    "\n",
    "x_encoded = soft_encode(x, l_lower, l_upper)\n",
    "\n",
    "print(x_encoded)\n",
    "print(soft_decode(x_encoded, l_lower, l_upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloatingBoxesEncoder(layers.Layer):\n",
    "    def __init__(self, psi, lower_boundary, upper_boundary, soft=True, **kwargs):\n",
    "        super(FloatingBoxesEncoder, self).__init__(**kwargs)\n",
    "\n",
    "        dims = lower_boundary.shape[1]\n",
    "        if upper_boundary.shape[1] != dims:\n",
    "            raise ValueError()\n",
    "\n",
    "        self.psi = psi\n",
    "        self.dims = dims\n",
    "        self.lower_boundary = lower_boundary\n",
    "        self.upper_boundary = upper_boundary\n",
    "        self.soft = soft\n",
    "\n",
    "        return\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.lower_ratio = self.add_weight(\n",
    "            name=\"lower_ratio\",\n",
    "            shape=(self.psi, self.dims),\n",
    "            initializer=tf.random_uniform_initializer(minval=0, maxval=1),\n",
    "            constraint=lambda x: tf.clip_by_value(x, 0, 1),\n",
    "            trainable=True,\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "        self.size_ratio = self.add_weight(\n",
    "            name=\"size_ratio\",\n",
    "            shape=(self.psi, self.dims),\n",
    "            initializer=tf.random_uniform_initializer(minval=0, maxval=1),\n",
    "            constraint=lambda x: tf.clip_by_value(x, 0, 1),\n",
    "            trainable=True,\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "        super(FloatingBoxesEncoder, self).build(input_shape)\n",
    "\n",
    "    def get_box_boundaries(self):\n",
    "        lower_bounds = (\n",
    "            self.upper_boundary - self.lower_boundary\n",
    "        ) * self.lower_ratio + self.lower_boundary\n",
    "        upper_bounds = (\n",
    "            self.upper_boundary - lower_bounds\n",
    "        ) * self.size_ratio + lower_bounds\n",
    "        return lower_bounds, upper_bounds\n",
    "\n",
    "    def call(self, inputs):\n",
    "        lower_bounds, upper_bounds = self.get_box_boundaries()\n",
    "        if self.soft:\n",
    "            return soft_encode(inputs, lower_bounds, upper_bounds)\n",
    "        else:\n",
    "            return hard_encode(inputs, lower_bounds, upper_bounds)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"psi\": self.psi,\n",
    "                \"dims\": self.dims,\n",
    "                \"soft\": self.soft,\n",
    "                \"lower_boundary\": self.lower_boundary.numpy(),\n",
    "                \"upper_boundary\": self.upper_boundary.numpy(),\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "class FloatingBoxesDecoder(layers.Layer):\n",
    "    def __init__(self, box_lower_boundaries, box_upper_boundaries, soft=True, **kwargs):\n",
    "        super(FloatingBoxesDecoder, self).__init__(**kwargs)\n",
    "\n",
    "        psi, dims = box_lower_boundaries.shape\n",
    "        if (\n",
    "            psi != box_upper_boundaries.shape[0]\n",
    "            or dims != box_upper_boundaries.shape[1]\n",
    "        ):\n",
    "            raise ValueError()\n",
    "\n",
    "        if len(box_lower_boundaries.shape) != 2 or len(box_upper_boundaries.shape) != 2:\n",
    "            raise ValueError()\n",
    "\n",
    "        if tf.reduce_any(box_lower_boundaries > box_upper_boundaries):\n",
    "            raise ValueError()\n",
    "\n",
    "        self.psi = psi\n",
    "        self.dims = dims\n",
    "        self.box_lower_boundaries = box_lower_boundaries\n",
    "        self.box_upper_boundaries = box_upper_boundaries\n",
    "        \n",
    "        self.soft = soft\n",
    "\n",
    "        return\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.soft:\n",
    "            return soft_decode(inputs, self.box_lower_boundaries, self.box_upper_boundaries)\n",
    "        else:\n",
    "            return hard_decode(inputs, self.box_lower_boundaries, self.box_upper_boundaries)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"psi\": self.psi,\n",
    "                \"dims\": self.dims,\n",
    "                \"soft\": self.soft,\n",
    "                \"box_lower_boundaries\": self.box_lower_boundaries.numpy(),\n",
    "                \"box_upper_boundaries\": self.box_upper_boundaries.numpy(),\n",
    "            }\n",
    "        )\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.1]\n",
      " [0.2]\n",
      " [0.5]\n",
      " [0.8]], shape=(4, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.48147973]\n",
      " [0.45885518]\n",
      " [0.5158565 ]\n",
      " [0.6249186 ]], shape=(4, 1), dtype=float32)\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 0.0609\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0609\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0609\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0609\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0609\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0609\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0609\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0609\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0609\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0609\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0609\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0609\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0609\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0609\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0609\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0609\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0609\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0609\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0609\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0609\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0609\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0609\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0609\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0609\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0609\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0609\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0609\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0609\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0609\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0609\n",
      "tf.Tensor(\n",
      "[[0.48147973]\n",
      " [0.45885518]\n",
      " [0.5158565 ]\n",
      " [0.6249186 ]], shape=(4, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def build_autoencoder(psi, lower, upper, soft=True):\n",
    "    inputs = keras.Input(name=\"inputs_x\", shape=(lower.shape[1],))\n",
    "    encoder = FloatingBoxesEncoder(psi, lower, upper, soft)\n",
    "    encoded = encoder(inputs)\n",
    "    box_lower_bounds, box_upper_bounds = encoder.get_box_boundaries()\n",
    "    decoder = FloatingBoxesDecoder(box_lower_bounds, box_upper_bounds, soft)\n",
    "    outputs = decoder(encoded)\n",
    "\n",
    "    model = keras.Model(\n",
    "        name=\"floating_boxes_autoencoder\", inputs=inputs, outputs=outputs\n",
    "    )\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=1e-10))\n",
    "    return model, encoder, decoder\n",
    "\n",
    "x = tf.constant(\n",
    "    [\n",
    "        [0.1],\n",
    "        [0.2],\n",
    "        [0.5],\n",
    "        [0.8],\n",
    "    ]\n",
    ")\n",
    "\n",
    "lower = tf.constant([[0.0]])\n",
    "upper = tf.constant([[1.0]])\n",
    "print(x)\n",
    "autoencoder, encoder, decoder = build_autoencoder(100, lower, upper, soft=True)\n",
    "print(autoencoder(x))\n",
    "autoencoder.fit(\n",
    "    x,\n",
    "    x,\n",
    "    epochs=epochs,\n",
    "    batch_size=2,\n",
    ")\n",
    "print(autoencoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"floating_boxes_autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs_x (InputLayer)       [(None, 1)]               0         \n",
      "                                                                 \n",
      " floating_boxes_encoder_1 (F  (None, 100)              200       \n",
      " loatingBoxesEncoder)                                            \n",
      "                                                                 \n",
      " floating_boxes_decoder_1 (F  (None, 1)                0         \n",
      " loatingBoxesDecoder)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "# plot_model(autoencoder, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# plt.axis(\"off\")\n",
    "# plt.imshow(mpimg.imread('model_plot.png'))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ds_train_raw, ds_test_raw), ds_info = tfds.load(\n",
    "#     \"mnist\",\n",
    "#     split=[\"train\", \"test\"],\n",
    "#     shuffle_files=False,\n",
    "#     as_supervised=True,\n",
    "#     with_info=True,\n",
    "# )\n",
    "\n",
    "# n_classes = ds_info.features[\"label\"].num_classes\n",
    "# n = ds_info.splits[\"train\"].num_examples\n",
    "\n",
    "\n",
    "# def normalize_img(image, label):\n",
    "#     image = tf.cast(image, tf.float32) / 255.0\n",
    "#     image = layers.Resizing(image_h, image_w)(image)\n",
    "#     image = tf.reshape(image, [-1])\n",
    "#     label = tf.one_hot(tf.cast(label, tf.int32), n_classes)\n",
    "#     label = tf.cast(label, tf.float32)\n",
    "#     return image, label\n",
    "\n",
    "\n",
    "# ds_train_normalized = ds_train_raw.map(\n",
    "#     normalize_img, num_parallel_calls=tf.data.AUTOTUNE\n",
    "# ).cache()\n",
    "\n",
    "# ds_test_normalized = ds_test_raw.map(\n",
    "#     normalize_img, num_parallel_calls=tf.data.AUTOTUNE\n",
    "# ).cache()\n",
    "\n",
    "\n",
    "# def prepare(ds, batch_size=batch_size):\n",
    "#     return ds.shuffle(n).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# dims = list(ds_train_normalized.take(1))[0][0].shape[0]\n",
    "\n",
    "# print(\"n: \", n, \"n_classes: \", n_classes, \"dims: \", dims)\n",
    "\n",
    "\n",
    "# def minmax_reducer(current, input):\n",
    "#     X, _ = input\n",
    "#     return (\n",
    "#         tf.reduce_min([current[0], X], axis=0),\n",
    "#         tf.reduce_max([current[0], X], axis=0),\n",
    "#     )\n",
    "\n",
    "\n",
    "# x0, _ = list(ds_train_normalized.take(1))[0]\n",
    "# min_train, max_train = ds_train_normalized.reduce((x0, x0), minmax_reducer)\n",
    "\n",
    "\n",
    "# lower = tf.expand_dims(min_train, axis=0)\n",
    "# upper = tf.expand_dims(max_train, axis=0)\n",
    "\n",
    "# autoencoder, lower_bounds, upper_bounds = build_autoencoder(10, lower, upper)\n",
    "# ds = (prepare(ds_train_normalized),)\n",
    "# autoencoder.fit(\n",
    "#     ds,\n",
    "#     ds,\n",
    "#     epochs=epochs,\n",
    "#     batch_size=batch_size,\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
